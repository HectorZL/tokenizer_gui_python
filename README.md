## ğŸŒŸ Proyecto: Tokenizador ğŸ“‚

Â¡Este proyecto ofrece una aplicaciÃ³n con interfaz grÃ¡fica (GUI) para dividir archivos de texto grandes en fragmentos mÃ¡s pequeÃ±os, usando el poderoso *tokenizador BERT* de la biblioteca Transformers! Perfecto para proyectos de procesamiento de lenguaje natural (NLP). ğŸ§ 

---

### ğŸš€ PreparaciÃ³n del Entorno ğŸŒ

1. **Crea un Entorno Virtual:** Es recomendable usar un entorno virtual para manejar las dependencias del proyecto.
   ```bash
   python3 -m venv .venv
   ```
2. **Activa el Entorno:**
   - **Linux/macOS:** `source .venv/bin/activate`
   - **Windows:** `.venv\Scripts\activate`
3. **Instala Requerimientos:** Instala los paquetes necesarios:
   ```bash
   pip install -r requirements.txt
   ```

---

### ğŸ“‚ Estructura del Proyecto

- **`gui.py`**: ImplementaciÃ³n de la GUI con PyQt5. ğŸ–¼ï¸ Ofrece una interfaz para seleccionar archivos, configurar lÃ­mites de tokens, y activar los procesos.
- **`logic.py`**: ğŸ’¡ Contiene la lÃ³gica de tokenizaciÃ³n y divisiÃ³n de archivos usando el tokenizador BERT de la biblioteca `transformers`.
- **`main.py`**: El punto de inicio del programa. Inicia la aplicaciÃ³n PyQt5 y muestra la interfaz grÃ¡fica.

---

### ğŸ”„ Flujo de Trabajo

1. **SelecciÃ³n de Archivo:** Selecciona el archivo de texto grande desde la interfaz grÃ¡fica. ğŸ“œ
2. **Establecer LÃ­mite de Tokens:** Ingresa el nÃºmero deseado de tokens por archivo.
3. **TokenizaciÃ³n:** `logic.py` usa el tokenizador BERT para procesar el texto. ğŸ§©
4. **DivisiÃ³n de Archivos:** El archivo se divide en varios fragmentos, cada uno con la cantidad de tokens especificada.
5. **Resultado:** La app te notifica sobre el Ã©xito de la divisiÃ³n y muestra el total de tokens procesados. âœ”ï¸

---

### âœ¨ Funcionalidades

- **Interfaz GrÃ¡fica (GUI)**: Â¡FÃ¡cil de usar y amigable para el usuario! ğŸ‰
- **Tokenizador BERT**: TokenizaciÃ³n robusta y precisa para dividir el texto. ğŸ”
- **LÃ­mites Ajustables**: Elige la cantidad de tokens por archivo segÃºn tus necesidades. âš™ï¸
- **Salida Limpia**: Los archivos resultantes contienen texto tokenizado limpio y listo para su uso. âœ¨

---

### ğŸƒâ€â™‚ï¸ CÃ³mo Ejecutar

1. Lanza la aplicaciÃ³n ejecutando `main.py`:
   ```bash
   python main.py
   ```

---

### ğŸ“Œ Notas Adicionales

- Los recursos (imÃ¡genes) para el tema de la GUI estÃ¡n en la carpeta `resources`.
- Todas las dependencias estÃ¡n listadas en el archivo `requirements.txt`.

Con esta herramienta, tendrÃ¡s una soluciÃ³n prÃ¡ctica para tokenizar y dividir archivos grandes, ideal para tareas de procesamiento de lenguaje natural. Â¡Disfruta el proceso de preparaciÃ³n de datos! ğŸŒˆ